- en: Deploying Your First Project
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署你的第一个项目
- en: Throughout this book so far, we have looked at the various ways we can run builds
    and containers using the Ansible Container workflow. We learned about running
    containers in a local Docker daemon, pushing built containers to a remote Docker
    image repository, managing container images, and even running containers at scale
    using container orchestration tools such as Kubernetes and OpenShift. We have
    almost come full circle, demonstrating the rich capabilities of Ansible Container
    and how it can be leveraged as a fully functional tool for building, running,
    and testing container images throughout an application's life cycle.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，在本书中，我们已经研究了如何使用 Ansible Container 工作流运行构建和容器的各种方式。我们了解了如何在本地 Docker 守护进程中运行容器，将构建的容器推送到远程
    Docker 镜像仓库，管理容器镜像，甚至使用 Kubernetes 和 OpenShift 等容器编排工具在大规模上运行容器。我们几乎已经展示了 Ansible
    Container 的全部功能，并演示了如何将其作为一个完整的工具，用于在应用程序生命周期中构建、运行和测试容器镜像。
- en: 'However, there is one aspect of the Ansible Container workflow we have not
    yet looked at in depth. In previous chapters, we alluded to the `deploy` command,
    and how `deploy` can be leveraged to run containers in production environments,
    or on remote systems. Now that we have covered a lot of the basics of how Docker,
    Kubernetes, and OpenShift work, it is time we turned our attention to the final
    Ansible Container workflow component: `ansible-container deploy`. It is my goal
    that, by reading through this chapter and following along with the examples, it
    will become evident to the reader that Ansible Container is more than a tool used
    to build and run container images locally. It is a robust tool for complex containerized
    application deployments across a variety of popular container platforms.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Ansible Container 工作流中有一个方面我们还没有深入研究。在之前的章节中，我们提到了 `deploy` 命令，以及如何利用 `deploy`
    在生产环境或远程系统中运行容器。现在，我们已经涵盖了 Docker、Kubernetes 和 OpenShift 的许多基础知识，是时候将注意力转向 Ansible
    Container 工作流的最后一个组件：`ansible-container deploy`。我的目标是，通过阅读本章并跟随示例，读者将清楚地意识到 Ansible
    Container 不仅仅是一个用来本地构建和运行容器镜像的工具。它是一个强大的工具，可以在各种流行的容器平台上进行复杂的容器化应用部署。
- en: 'Throughout this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Overview of ansible-container deploy
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ansible-container deploy 概述
- en: Deploying containers to Kubernetes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将容器部署到 Kubernetes
- en: Deploying containers to OpenShift
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将容器部署到 OpenShift
- en: Overview of ansible-container deploy
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ansible-container deploy 概述
- en: 'The `ansible-container deploy` command is the component of the Ansible Container
    workflow that is responsible for, you guessed it, deploying containers to remote
    container service engines. At the time of writing, these engines include Docker,
    Kubernetes, and OpenShift. By leveraging configuration in the `container.yml`
    file, Ansible Container has the ability to authenticate to these services and
    leverage API calls to start containers according to the configuration specified
    by the user. Deployment with Ansible Container is a two-step process. First, Ansible
    Container pushes the built container images to a remote image registry, similar
    to Docker Hub or `Quay.io`. This enables the remote container runtime service
    to have access to the containers during the deployment process. Second, Ansible
    Container generates deployment playbooks that can be executed locally and performs
    the deployment using the `ansible-container run` command. Working through the
    deploy process can be a little confusing at first. The following flowchart demonstrates
    the deployment process after first building and running a project locally:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '`ansible-container deploy` 命令是 Ansible Container 工作流的一个组件，负责，如你所猜测的那样，将容器部署到远程容器服务引擎。在写本文时，这些引擎包括
    Docker、Kubernetes 和 OpenShift。通过利用 `container.yml` 文件中的配置，Ansible Container 能够验证这些服务并通过
    API 调用启动容器，按照用户指定的配置进行部署。使用 Ansible Container 进行部署是一个两步过程。首先，Ansible Container
    将构建好的容器镜像推送到远程镜像仓库，类似于 Docker Hub 或 `Quay.io`。这使得远程容器运行时服务能够在部署过程中访问容器。第二，Ansible
    Container 生成可以在本地执行的部署剧本，并使用 `ansible-container run` 命令执行部署。刚开始时，部署过程可能会有些混乱。下面的流程图展示了在本地构建并运行项目后的部署过程：'
- en: '![](img/fa204a2c-74c0-4408-9f86-a0518a29f1af.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fa204a2c-74c0-4408-9f86-a0518a29f1af.png)'
- en: 'Figure 1: ansible-container deploy workflow'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：ansible-container deploy 工作流
- en: We are going to start out by looking at examples using our simple NGINX container
    project. Later, we are going to look at deploying examples to Kubernetes and OpenShift
    using the MariaDB project we built in [Chapter 4](747fd1c6-46e4-424a-be59-5bbf20deb5ed.xhtml),
    *What's in a Role?*
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从使用简单的NGINX容器项目的示例开始。稍后，我们将查看使用我们在[第4章](747fd1c6-46e4-424a-be59-5bbf20deb5ed.xhtml)中构建的MariaDB项目将其部署到Kubernetes和OpenShift的示例，*角色中有什么？*
- en: ansible-container deploy
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ansible-container deploy
- en: 'Before we start looking at `ansible-container deploy`, let''s first rebuild
    the NGINX project we created earlier. In your Ubuntu Vagrant lab VM, navigate
    to the `/vagrant/AnsibleContainer/nginx_demo` directory; or, if you built this
    example yourself in another directory, navigate to it and run the `ansible-container
    build` command. This will make sure that the lab VM has a fresh build of the project:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始查看`ansible-container deploy`之前，首先让我们重新构建之前创建的NGINX项目。在您的Ubuntu Vagrant实验室虚拟机中，导航到`/vagrant/AnsibleContainer/nginx_demo`目录；或者，如果您在其他目录中自行构建了这个示例，请导航到该目录并运行`ansible-container
    build`命令。这将确保实验室虚拟机有一个项目的全新构建：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You can validate that the project has successfully been built and the container
    images are cached by running the `docker images` command:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过运行`docker images`命令来验证项目是否已成功构建并且容器镜像已被缓存：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now that we have the container cached locally, we can use the `ansible-container
    deploy` command to simulate project deployment. Without providing any arguments
    about what engine we will deploy our container to, `ansible-container deploy`
    will generate playbooks that can be used to deploy our project onto a local or
    remote host that is running Docker. It will also push our project to the registries
    configured in the `container.yml` file located in the `root` directory of our
    project. Due to the fact that `deploy` leverages much of the same functionality
    as `ansible-container push`, we will provide `deploy` with the same flags we would
    provide the `push` command concerning our container image registry. In this case,
    we will tell it to push to our Docker Hub registry, as we will provide the username
    for our account and any tags we want to use to differentiate this version of the
    container from previous versions. For the purposes of demonstration, we will use
    the `deploy` tag:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经在本地缓存了容器，我们可以使用`ansible-container deploy`命令来模拟项目部署。如果不提供关于将容器部署到哪个引擎的任何参数，`ansible-container
    deploy`将生成可用于将我们的项目部署到运行Docker的本地或远程主机上的剧本。它还会将我们的项目推送到在项目`root`目录中找到的`container.yml`文件中配置的注册表。由于`deploy`与`ansible-container
    push`使用了许多相同的功能，我们将向`deploy`提供与`push`命令相同的标志，关于容器镜像注册表。在这种情况下，我们将告诉它将容器推送到我们的Docker
    Hub注册表，因为我们将提供帐户的用户名以及任何我们希望用来区分该版本容器与以前版本的标签。为了演示目的，我们将使用`deploy`标签：
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The deploy process, in a similar fashion to the push process, will prompt you
    for the password for your Docker Hub account. Upon successful authentication,
    it will push your container image layers to the container image registry. So far,
    this might look exactly identical to the push process. However, you may notice
    that, in the `root` directory of your project, a new directory called `ansible-deployment`
    now exists. Within this directory, you will find a single Ansible playbook that
    is named identically to that of your project, `nginx_demo`. Here is a sample of
    what this playbook looks like:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 部署过程与推送过程类似，会提示您输入Docker Hub帐户的密码。在成功认证后，它将把您的容器镜像层推送到容器镜像注册表。到目前为止，这看起来与推送过程完全相同。然而，您可能会注意到，在项目的`root`目录中，现在存在一个名为`ansible-deployment`的新目录。在这个目录中，您将找到一个与您的项目同名的Ansible剧本，名为`nginx_demo`。以下是该剧本的示例：
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You may have to ensure the `image` line reflects the image path in this format, `docker.io/username/containername:tag`,
    as some versions of Ansible Container supply the wrong path as input in the playbook.
    If this is the case, simply modify the playbook in a text editor.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能需要确保`image`行反映了以下格式的镜像路径，`docker.io/username/containername:tag`，因为某些版本的Ansible
    Container会在剧本中提供错误的路径。如果是这种情况，只需在文本编辑器中修改剧本。
- en: The deploy playbook works by making calls to the `docker_service` module running
    on the target hosts. By default, the container uses `localhost` as the target
    host for deployment. However, you can easily provide a standard Ansible inventory
    file to have this project run on remote hosts. The deploy playbook supports full
    Docker life cycle application management, such as starting the container, restarting,
    and ultimately destroying the project by providing a series of playbook tags to
    conditionally execute the desired functionality. You may notice that the playbook
    inherits many of the settings we configured in the `container.yml` file. Ansible
    Container uses these settings so that the playbooks can be executed independently
    of the project itself.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 部署 playbook 通过调用运行在目标主机上的 `docker_service` 模块来工作。默认情况下，容器使用 `localhost` 作为部署的目标主机。然而，你可以轻松地提供一个标准的
    Ansible 清单文件，让这个项目在远程主机上运行。部署 playbook 支持完整的 Docker 生命周期应用管理，例如启动容器、重启容器，最终通过提供一系列
    playbook 标签有条件地执行所需功能来销毁项目。你会发现 playbook 继承了我们在 `container.yml` 文件中配置的许多设置。Ansible
    Container 使用这些设置，使得 playbooks 可以独立于项目本身执行。
- en: 'Since we have already looked at using `ansible-container run` to run our containers
    locally throughout this book,  let''s try executing the playbook directly to start
    the container. This mimics the same process used if you want to manually run a
    deployment outside of the Ansible Container workflow. This can be accomplished
    by using the `ansible-playbook` command with the `start` tag to deploy a project
    on our localhost. You may notice that this process is exactly the same process
    as running the `ansible-container run` command. It is important to note that any
    of the core Ansible Container functionality (run, restart, stop, and destroy)
    can be executed independently of Ansible Container by running playbooks directly
    and supplying the appropriate tag according to the functionality you are trying
    to achieve:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经在本书中通过使用 `ansible-container run` 运行本地容器，接下来让我们尝试直接执行 playbook 启动容器。这模拟了如果你希望手动运行部署而不依赖
    Ansible Container 工作流时的相同过程。可以通过使用 `ansible-playbook` 命令并传递 `start` 标签来在本地主机上部署项目。你会发现这个过程和运行
    `ansible-container run` 命令的过程完全相同。需要注意的是，任何核心的 Ansible Container 功能（如 run、restart、stop
    和 destroy）都可以通过直接运行 playbooks，并根据你想要实现的功能传递相应的标签来独立执行，而不依赖 Ansible Container：
- en: '[PRE4]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once the playbook execution has completed, `PLAY RECAP` will show that one
    task has executed a change on your localhost. You can execute the `docker ps -a`
    command to confirm the project has successfully been deployed:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 playbook 执行完成，`PLAY RECAP` 会显示一个任务已在你的本地主机上执行了更改。你可以执行 `docker ps -a` 命令确认项目已成功部署：
- en: '[PRE5]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In a similar way, we can run this playbook again, passing in the `--restart`
    tag to restart the container on the Docker host. After executing the playbook
    for a second time, you should see that a single task has once more changed, indicating
    the container has been restarted. This mimics the functionality that the `ansible-container
    restart` command provides. The `status` column in `docker ps -a` will show that
    the container has only been up for a handful of seconds after executing the restart:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 以类似的方式，我们可以再次运行此 playbook，传递 `--restart` 标签以重新启动 Docker 主机上的容器。执行 playbook 第二次后，你应该会看到一个任务再次发生了变化，表示容器已被重新启动。这模拟了
    `ansible-container restart` 命令的功能。`docker ps -a` 中的 `status` 列将显示容器在执行重启后只运行了几秒钟：
- en: '[PRE6]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The `stop` tag can be passed into the `ansible-playbook` command to temporarily
    stop the running container. Similar to `restart`, the `docker ps -a` output will
    show that the container is in an `exit` status:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`stop` 标签可以传递给 `ansible-playbook` 命令，以暂时停止正在运行的容器。与 `restart` 类似，`docker ps
    -a` 输出将显示容器处于 `exit` 状态：'
- en: '[PRE7]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We can now check the status using `docker ps -a` command:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用 `docker ps -a` 命令检查状态：
- en: '[PRE8]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Finally, the project can be removed entirely from our Docker host by passing
    in the `destroy` tag. Running this `playbook` tag will execute a few more steps
    in the playbook, but will ultimately remove all traces of your project from the
    host:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，可以通过传递 `destroy` 标签将项目从 Docker 主机上完全移除。运行这个 `playbook` 标签会在 playbook 中执行更多的步骤，但最终会将项目的所有痕迹从主机上删除：
- en: '[PRE9]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Behind the scenes, when any of the core Ansible Container commands are executed,
    they are essentially wrappers around the same playbook that gets generated as
    a part of your project. The purpose of this portion of the chapter was to demonstrate
    to the reader the overall flow of deploying projects using Ansible Container locally,
    and to build upon these skills deeper in the lesson. Where deployment gets really
    interesting is when using Kubernetes and OpenShift as the target deployment engines.
    Using the Ansible Container workflow commands with the corresponding container
    platform engine, we can manage containerized deployments directly using the Ansible
    Container workflow commands instead of executing the playbooks directly.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，当执行任何核心Ansible Container命令时，它们本质上是围绕生成的项目中的相同playbook的包装器。本章这一部分的目的是向读者展示如何使用Ansible
    Container在本地部署项目的整体流程，并在课程中更深入地讲解这些技能。部署真正变得有趣的是当使用Kubernetes和OpenShift作为目标部署引擎时。通过使用Ansible
    Container工作流命令与相应的容器平台引擎，我们可以直接使用Ansible Container工作流命令管理容器化部署，而不是直接执行playbooks。
- en: Deploying containers to Kubernetes
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署容器到Kubernetes
- en: One of the many aspects that makes the Ansible Container workflow so flexible
    and appealing to organizations and individuals looking to adopt Ansible as the
    native support for remote deployments using Kubernetes and OpenShift. In this
    section, we will look at using the `ansible-container deploy` command to deploy
    our containers to our Google Cloud Kubernetes cluster we created in [Chapter 5](ccc07e61-25e7-4984-953b-586b28b12aab.xhtml),
    C*ontainers at Scale with Kubernetes*.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 使Ansible Container工作流如此灵活且吸引组织和个人采用Ansible作为使用Kubernetes和OpenShift进行远程部署的原生支持的一大原因之一。在本节中，我们将使用`ansible-container
    deploy`命令将容器部署到我们在[第5章](ccc07e61-25e7-4984-953b-586b28b12aab.xhtml)中创建的Google
    Cloud Kubernetes集群，*Kubernetes下的容器规模管理*。
- en: As we discussed in the previous section, running `ansible-container deploy`
    by itself will, by default, push your container to any image registries you have
    configured in your `container.yml` file and generate a new directory in the `root`
    of your project called `ansible-deployment`. Inside of this directory, a single
    YAML playbook file named after the project will be present. This playbook is used
    to deploy your container to any Docker host, quite similar to the `ansible-container
    run` command. For the purposes of this example, we are going to run `ansible-container
    deploy` using the Kubernetes engine so we can leverage Ansible Container as a
    deployment tool for Kubernetes, creating service definitions and deployment abstractions
    automatically.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一节中讨论的那样，单独运行`ansible-container deploy`将默认将容器推送到你在`container.yml`文件中配置的任何镜像仓库，并在项目的`root`目录下生成一个名为`ansible-deployment`的新目录。在该目录中，将存在一个以项目名称命名的单个YAML
    playbook文件。这个playbook用于将容器部署到任何Docker主机，类似于`ansible-container run`命令。为了这个示例，我们将使用Kubernetes引擎运行`ansible-container
    deploy`，这样我们就可以利用Ansible Container作为Kubernetes的部署工具，自动创建服务定义和部署抽象。
- en: In order to enable the Kubernetes to deploy functionality in Ansible Container,
    we will add a couple of new parameters to the project `container.yml` file. Specifically,
    we need to point our project to our Kubernetes authentication configuration file,
    and define the namespace our container operates in within Kubernetes. For this
    example, I will use our previously used MariaDB project, but with a few modifications
    to the `container.yml` file to support Kubernetes.  For reference, this project
    can be found in the official Git repository for this book, in the  `Kubernetes/mariadb_demo_k8s` directory.
    Feel free to follow along, or modify the existing MariaDB project to support Kubernetes.
    In the settings section, we will add the `k8s_namespace` and `k8s_auth`.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使Kubernetes能够在Ansible Container中部署功能，我们将在项目的`container.yml`文件中添加几个新参数。具体来说，我们需要将项目指向Kubernetes认证配置文件，并定义容器在Kubernetes中的命名空间。作为示例，我将使用我们之前使用的MariaDB项目，但对`container.yml`文件做一些修改以支持Kubernetes。作为参考，该项目可以在本书的官方Git仓库中找到，位于`Kubernetes/mariadb_demo_k8s`目录下。欢迎跟随示例，也可以修改现有的MariaDB项目以支持Kubernetes。在设置部分，我们将添加`k8s_namespace`和`k8s_auth`。
- en: The Kubernetes `namespace` will contain the name of the namespace in our cluster
    we want to deploy our project into, and the `auth` section will provide the path
    to our Kubernetes authentication configuration file. The default location of the
    Kubernetes authentication configuration is `/home/user/.kube/config`. If you are
    following along using the Vagrant lab, Google Cloud SDK places this configuration
    file at `/home/ubuntu/.kube/config`.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes `namespace` 将包含我们希望部署项目的集群中的命名空间名称，而 `auth` 部分将提供 Kubernetes 认证配置文件的路径。Kubernetes
    认证配置的默认位置是 `/home/user/.kube/config`。如果你正在使用 Vagrant 实验室，Google Cloud SDK 会将该配置文件放置在
    `/home/ubuntu/.kube/config`。
- en: 'Before we can begin, though, we need to set up a default access token in order
    for Ansible Container to access the Google Cloud API. We can do this by executing
    the `gcloud auth application-default login` command. Executing this command will
    provide you with a hyperlink you can use to allow permissions to the Google Cloud
    API using your Google login credentials, similar to what we did in [Chapter 5](ccc07e61-25e7-4984-953b-586b28b12aab.xhtml),
    *Containers at Scale with Kubernetes*. The Google Cloud API will give you a token
    you can enter at the command line that will generate an application default credentials
    file, located at `/home/ubuntu/.config/gcloud/application_default_credentials.json`:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在开始之前，我们需要设置一个默认的访问令牌，以便 Ansible Container 可以访问 Google Cloud API。我们可以通过执行
    `gcloud auth application-default login` 命令来做到这一点。执行此命令将为你提供一个超链接，允许你使用 Google
    登录凭证授予对 Google Cloud API 的权限，类似于我们在[第 5 章](ccc07e61-25e7-4984-953b-586b28b12aab.xhtml)中做的，*使用
    Kubernetes 扩展容器*。Google Cloud API 将为你提供一个令牌，你可以在命令行输入该令牌，从而生成一个位于 `/home/ubuntu/.config/gcloud/application_default_credentials.json`
    的应用程序默认凭证文件：
- en: '[PRE10]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: These credentials will be used by any library that requests access to any Google
    Cloud resources, including Ansible Container.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这些凭证将被任何请求访问 Google Cloud 资源的库使用，包括 Ansible Container。
- en: The Google Container Engineer-specific steps are only required if you are using
    a Google Cloud Kubernetes cluster. You can skip these step if you are using a
    local Kubernetes environment such as Minikube.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 仅在你使用 Google Cloud Kubernetes 集群时，才需要进行 Google Container Engineer 特定的步骤。如果你使用的是像
    Minikube 这样的本地 Kubernetes 环境，可以跳过这些步骤。
- en: 'Now that we have the proper permissions set in the Google Cloud API, we can
    modify the `container.yml` file of our MariaDB project to support the Kubernetes
    deployment engine:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已在 Google Cloud API 中设置了适当的权限，我们可以修改 MariaDB 项目的 `container.yml` 文件，以支持
    Kubernetes 部署引擎：
- en: '[PRE11]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You will notice the following changes we have made to support the Kubernetes
    deployment:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 你将注意到我们已做出以下更改以支持 Kubernetes 部署：
- en: '`project_name`: For this example, we have added a field in the `settings` block
    called `project_name`. Throughout this book, we have allowed our projects to take
    the default name of the directory that it is built in. Kubernetes is limited as
    to the characters it can use to define services and pods, so we want to ensure
    we do not use illegal characters in our project name by overriding them in the
    `container.yml` file.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`project_name`：在这个示例中，我们在 `settings` 块中添加了一个名为 `project_name` 的字段。在本书中，我们允许我们的项目使用其构建目录的默认名称。由于
    Kubernetes 对于定义服务和 Pod 使用的字符有限制，我们希望通过在 `container.yml` 文件中覆盖它们来确保项目名称中不包含非法字符。'
- en: '`k8s_namespace`: This defines the Kubernetes namespace we will deploy our pods
    into. Leaving this stanza blank will cause Ansible Container to use the default
    namespace that we used in our NGINX deployment earlier in the chapter. In this
    example, we will use a different namespace called `database`.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`k8s_namespace`：这定义了我们将部署 Pod 的 Kubernetes 命名空间。如果将此部分留空，Ansible Container
    将使用我们在本章早些时候的 NGINX 部署中使用的默认命名空间。在此示例中，我们将使用一个名为 `database` 的不同命名空间。'
- en: '`k8s_auth`: This is where we specify the location of our Kubernetes authentication
    configuration file. Within this file, Ansible Container is able to extract the
    IP address of our API server, the access credentials to create resources in the
    cluster, as well as the SSL certificates required to connect to Kubernetes.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`k8s_auth`：这是我们指定 Kubernetes 认证配置文件位置的地方。在该文件中，Ansible Container 能够提取我们的 API
    服务器的 IP 地址、用于在集群中创建资源的访问凭证，以及连接 Kubernetes 所需的 SSL 证书。'
- en: 'Once these changes have been placed in your `container.yml` file, let''s build
    the project:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦这些更改被放入你的 `container.yml` 文件中，让我们开始构建项目：
- en: '[PRE12]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Once the project has finished building, we can use the `ansible-container deploy`
    command, specifying the `--engine` flag to use `k8s`, and providing the details
    for the Docker image registry we want to push to as configured in our `container.yml`
    file. For the sake of separation, let''s also tag the image version with `kubernetes`
    so we can keep this version separate in our repository. Ansible Container will
    then push our image to the Docker Hub repository and generate the deployment playbooks
    specific to Kubernetes:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦项目构建完成，我们可以使用`ansible-container deploy`命令，指定`--engine`标志来使用`k8s`，并提供我们在`container.yml`文件中配置的Docker镜像仓库的详细信息。为了实现版本分离，我们还可以使用`kubernetes`标签标记镜像版本，这样我们可以在仓库中将此版本区分开来。然后，Ansible
    Container会将我们的镜像推送到Docker Hub仓库，并生成特定于Kubernetes的部署剧本：
- en: K8s is shorthand for Kubernetes since Kubernetes comprises the letter K with
    8 letters after it. This is commonly pronounced in the community as **Kay-Eights**.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: K8s是Kubernetes的简写，Kubernetes由字母K和后面8个字母组成。在社区中，这通常被发音为**凯-艾特斯**。
- en: '[PRE13]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Once this process has completed, you will notice that, similar to the last
    example, a new directory has appeared in your project called `ansible-deployment`.
    Inside of this directory, you will find a single playbook and a `roles` directory
    that is responsible for performing the actual deployment of our service to Kubernetes.
    As with our previous localhost example, this playbook is likewise divided up based
    on tags that control starting, stopping, and restarting the service in our cluster.
    Since we have not yet deployed our service, we can start the deployment using
    the `ansible-container run` command with the `--engine k8s` flag to indicate a
    Kubernetes deployment. Assuming we have configured everything correctly in the
    `container.yml` file, you should see a successful playbook run, indicating the
    container has been deployed to the Kubernetes cluster:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦这个过程完成，您会注意到，类似于上一个示例，项目中出现了一个新的目录，名为`ansible-deployment`。在这个目录内，您会找到一个剧本和一个`roles`目录，后者负责将我们的服务部署到Kubernetes中。与我们之前的本地主机示例一样，这个剧本同样根据标签进行划分，控制在集群中启动、停止和重启服务。由于我们尚未部署我们的服务，因此我们可以使用带有`--engine
    k8s`标志的`ansible-container run`命令来启动部署，以指示进行Kubernetes部署。如果我们已经正确配置了`container.yml`文件，您应该看到剧本成功运行，表示容器已经部署到Kubernetes集群中：
- en: '[PRE14]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Using the `kubectl get pods` command from earlier, we can validate that our
    Kubernetes pod has been deployed and is successfully running. Since we deployed
    this particular pod in its own namespace, we need to use the `--namespace` flag
    to see pods that are running in other namespaces:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用之前的`kubectl get pods`命令，我们可以验证我们的Kubernetes pod已经部署并成功运行。由于我们将这个pod部署在自己的命名空间中，因此我们需要使用`--namespace`标志来查看运行在其他命名空间中的pods：
- en: '[PRE15]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Using the `ansible-container run` command with the Kubernetes engine is a powerful
    tool for creating cloud-native services that run on a Kubernetes cluster. Using
    Ansible Container, you have the flexibility to choose how you want to deploy applications,
    by executing the playbooks directly or automatically using the Ansible Container
    workflow. If you wish to delete the current deployment from your Kubernetes cluster,
    you can simply run the `ansible-container --engine k8s destroy` command to completely
    remove the pods and deployment artifacts from the cluster. It is important to
    note that the other Ansible Container workflow commands (start, stop, and restart)
    are perfectly applicable suffixes to use with the Kubernetes deployment engine.
    For the sake of reducing redundancy, let's take a look at how `ansible-container
    deploy` and the workflow commands work with the OpenShift deployment engine. Functionally,
    the Ansible Container workflow commands are identical for Kubernetes and OpenShift.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 使用带有Kubernetes引擎的`ansible-container run`命令是创建在Kubernetes集群上运行的云原生服务的强大工具。通过使用Ansible
    Container，您可以灵活地选择部署应用程序的方式，可以直接执行剧本，也可以通过Ansible Container工作流自动执行。如果您希望从Kubernetes集群中删除当前部署，您可以简单地运行`ansible-container
    --engine k8s destroy`命令，以完全从集群中删除pods和部署工件。需要注意的是，其他Ansible Container工作流命令（start、stop和restart）完全适用于Kubernetes部署引擎。为了减少冗余，我们来看一下`ansible-container
    deploy`和工作流命令在OpenShift部署引擎下的工作方式。从功能上讲，Ansible Container的工作流命令对于Kubernetes和OpenShift是相同的。
- en: Deploying containers to OpenShift
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将容器部署到OpenShift
- en: The `ansible-container deploy` command also supports deployments directly to
    OpenShift using the native OpenShift APIs. Since OpenShift is built on top of
    Kubernetes, you will discover that deploying containers to OpenShift is quite
    a similar process to Kubernetes deployments, since OpenShift authentication works
    very similarly to Kubernetes on the backend. Before beginning, these examples
    are going to use the Vagrant lab VM running at the same time as the Minishift
    VM we created in [Chapter 6](d3c6ddae-003d-4f20-a3a5-efd018ac61ee.xhtml), *Managing
    Containers with OpenShift*. This can get quite CPU and RAM intensive. If you're
    attempting to run these examples with 8 GB of RAM or higher, you should get good
    performance.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`ansible-container deploy`命令还支持使用原生OpenShift API直接部署到OpenShift。由于OpenShift是基于Kubernetes构建的，您会发现将容器部署到OpenShift的过程与Kubernetes的部署非常相似，因为OpenShift的身份验证与Kubernetes在后台的工作方式非常相似。在开始之前，这些示例将使用与我们在[第6章](d3c6ddae-003d-4f20-a3a5-efd018ac61ee.xhtml)中创建的Minishift虚拟机同时运行的Vagrant实验室虚拟机，*使用OpenShift管理容器*。这可能会消耗大量的CPU和内存。如果您尝试在8
    GB或更高的内存下运行这些示例，您应该能够获得良好的性能。'
- en: However, if you are constrained on resources, these examples can run reasonably
    well using the OpenShift free tier cloud account, although you may run into issues
    with the limited quotas provided.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果您的资源有限，这些示例仍然可以在OpenShift的免费云账户上运行得相当顺利，尽管您可能会遇到提供的配额有限的问题。
- en: 'Before beginning, we need to first ensure that the Vagrant lab environment,
    as well as our Minishift VM, are running and reachable from the VirtualBox network.
    Since the hypervisors used to create our Vagrant lab environment and our Minishift
    cluster are both using VirtualBox, we should by default have network connectivity
    between the two VMs. We can validate this by attempting to ping the Minishift
    VM from our Vagrant lab VM. First, we need to start the Minishift VM using reasonable
    specifications for your local workstation. In this example, I am going to start
    the Minishift VM allocating 8 GB of RAM and 50 GB virtual hard disk storage for
    it. If you are running both VMs simultaneously, you may only be able to allocate
    the minimum 2 GB of RAM for Minishift:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，我们首先需要确保Vagrant实验室环境以及我们的Minishift虚拟机正在运行，并且可以从VirtualBox网络中访问。由于用于创建我们Vagrant实验室环境和Minishift集群的虚拟化管理程序都使用VirtualBox，我们默认情况下应该能够在两个虚拟机之间建立网络连接。我们可以通过尝试从Vagrant实验室虚拟机ping
    Minishift虚拟机来验证这一点。首先，我们需要使用适合您本地工作站的规格启动Minishift虚拟机。在这个示例中，我将启动Minishift虚拟机，分配8
    GB内存和50 GB虚拟硬盘存储。如果您同时运行两个虚拟机，您可能只能为Minishift分配最小的2 GB内存：
- en: '[PRE16]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'At the end of the startup process, you should receive an IP from which the
    OpenShift Web UI is accessible. We need to ensure this IP address is reachable
    from our Vagrant lab node:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 启动过程结束时，您应该会收到一个IP地址，通过这个地址可以访问OpenShift Web UI。我们需要确保这个IP地址可以从我们的Vagrant实验室节点访问：
- en: '[PRE17]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'If this IP address is not pingable, you may have to configure your VirtualBox
    networking so that network connectivity is available. A great resource to learn
    more about configuring and debugging VirtualBox networks is the official VirtualBox
    documentation: [https://www.virtualbox.org/manual/ch06.html](https://www.virtualbox.org/manual/ch06.html).'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这个IP地址无法ping通，您可能需要配置您的VirtualBox网络，使网络连接可用。了解如何配置和调试VirtualBox网络的一个很好的资源是官方的VirtualBox文档：[https://www.virtualbox.org/manual/ch06.html](https://www.virtualbox.org/manual/ch06.html)。
- en: 'Once networking has been established and verified between the Minishift VM
    and the Vagrant lab VM, next we will need to install the OC on our Vagrant lab
    VM to allow us to authenticate to OpenShift. This will be the exact same process
    we completed in [Chapter 6](d3c6ddae-003d-4f20-a3a5-efd018ac61ee.xhtml), *Managing
    Containers with OpenShift*:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦Minishift虚拟机和Vagrant实验室虚拟机之间的网络连接已经建立并验证，接下来我们需要在Vagrant实验室虚拟机上安装OC，以便我们可以进行OpenShift身份验证。这将是我们在[第6章](d3c6ddae-003d-4f20-a3a5-efd018ac61ee.xhtml)中完成的相同过程，*使用OpenShift管理容器*：
- en: 'Download the OC binary packages using `wget`:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`wget`下载OC二进制包：
- en: '[PRE18]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Extract the TAR archive using the `tar -xf` command:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`tar -xf`命令提取TAR归档文件：
- en: '[PRE19]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Copy the binary to a `$PATH` location:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将二进制文件复制到`$PATH`位置：
- en: '[PRE20]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'If you have existing Kubernetes credentials in `/home/ubuntu/.kube/config`,
    you will need to back them up to another location so the OC does not overwrite
    them (or simply delete the config file if you have no further use for it any longer:
    `rm -rf ~/.kube/config`).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在`/home/ubuntu/.kube/config`中有现有的Kubernetes凭证，您需要将其备份到其他位置，以防OC覆盖它们（或者如果您不再需要它，只需删除配置文件：`rm
    -rf ~/.kube/config`）。
- en: 'Next, we need to authenticate to the local OpenShift cluster using the `oc
    login` command in order to generate our Kubernetes credential file that Ansible
    Container will leverage. The `oc login` command takes the URL endpoint of the
    OpenShift cluster as a parameter. By default, the OC will write a Kubernetes configuration
    file to `/home/ubuntu/.kube/config`. This file will serve as our means of authenticating
    to OpenShift Kubernetes to perform automated deployments. Remember to log in as
    the `developer` user, which uses any user-provided password to log in:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要使用`oc login`命令对本地 OpenShift 集群进行认证，以便生成 Kubernetes 凭证文件，该文件将由 Ansible
    Container 使用。`oc login`命令需要 OpenShift 集群的 URL 作为参数。默认情况下，OC 将把 Kubernetes 配置文件写入`/home/ubuntu/.kube/config`。此文件将作为我们认证
    OpenShift Kubernetes 以执行自动化部署的凭证。记得以 `developer` 用户身份登录，该用户使用任何用户提供的密码进行登录：
- en: '[PRE21]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Once you have successfully authenticated, you should notice there is now a
    new Kubernetes configuration file written to the path `/home/ubuntu/.kube/config`.
    This is the configuration file that Ansible Container will use for access to OpenShift:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您成功认证，您应该会注意到现在有一个新的 Kubernetes 配置文件被写入到路径`/home/ubuntu/.kube/config`。这是 Ansible
    Container 用于访问 OpenShift 的配置文件：
- en: '[PRE22]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Let''s test authentication to the local OpenShift instance by using the `oc
    get all` command. If authentication has been successful, you should see a list
    of pods, deployments, services, and routes currently running in your local OpenShift
    environment:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过使用`oc get all`命令测试对本地 OpenShift 实例的认证。如果认证成功，您应该会看到当前在本地 OpenShift 环境中运行的
    pod、部署、服务和路由的列表：
- en: '[PRE23]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'OpenShift, by default, leverages the same authentication mechanism that Kubernetes
    uses in our `container.yml` file. The only thing we need to provide is the path
    to our Kubernetes configuration file, as well as the Kubernetes namespace the
    project will be deployed into. Since we have previously configured this in our
    MariaDB project in the last section, let''s reuse this same configuration to deploy
    our project to OpenShift. As a review, let''s look at the content of our MariaDB
    project in the Vagrant Lab VM (`/vagrant/Kubernetes/mariadb_demo_k8s`), and look
    at the contents of the `container.yml` file:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，OpenShift 使用与 Kubernetes 相同的认证机制，在我们的`container.yml`文件中。我们需要提供的唯一信息是 Kubernetes
    配置文件的路径，以及项目将要部署到的 Kubernetes 命名空间。由于我们之前在上一部分的 MariaDB 项目中已经配置过这些内容，所以我们可以重用这些配置，将我们的项目部署到
    OpenShift。回顾一下，我们来看一下 Vagrant Lab 虚拟机（`/vagrant/Kubernetes/mariadb_demo_k8s`）中
    MariaDB 项目的内容，并查看`container.yml`文件的内容：
- en: '[PRE24]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The only difference here is that the `k8s_namespace` parameter will define
    which OpenShift project you want to deploy your container into. In OpenShift terminology,
    `project` and `namespace` are essentially identical. For now, let''s leave the
    configuration as is and look at how to deploy our project using the OpenShift
    engine. Deploying projects using OpenShift is very similar to how we deployed
    using Kubernetes, with the exception that we will prefix our Ansible Container
    commands with the `--engine openshift` flag so that our project will know to talk
    to the OpenShift API directly.  The same syntax rules apply here as well. We will
    give our `deploy` command the name of the repository defined in the `container.yml`
    file to push our container image to, and give it a unique tag to reference later:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的区别是，`k8s_namespace`参数将定义您希望将容器部署到的 OpenShift 项目。在 OpenShift 术语中，`project`和`namespace`本质上是相同的。目前，让我们保持配置不变，来看一下如何使用
    OpenShift 引擎部署我们的项目。使用 OpenShift 部署项目与我们使用 Kubernetes 部署的方式非常相似，唯一的区别是我们需要在 Ansible
    Container 命令前添加`--engine openshift`标志，以便我们的项目知道要直接与 OpenShift API 进行交互。这里也适用相同的语法规则。我们将为`deploy`命令提供在`container.yml`文件中定义的仓库名称，用于推送我们的容器镜像，并为其指定一个唯一的标签，方便后续引用：
- en: '[PRE25]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Once our container image has been pushed, we can validate the deployment playbooks
    have been generated in the `ansible-deployment` directory (`Kubernetes/mariadb_demo_k8s/ansible-deployment/mariadb-k8s.yml`):'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的容器镜像推送完成，我们可以验证部署的 playbooks 是否已经在`ansible-deployment`目录下生成（`Kubernetes/mariadb_demo_k8s/ansible-deployment/mariadb-k8s.yml`）：
- en: '[PRE26]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Similar to the Docker and Kubernetes deployment engines, these playbooks can
    be executed independently using the `ansible-playbook` command, or by using the
    `ansible-container run` command. Let''s run our project and deploy it into OpenShift
    using the `ansible-container run` command:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 Docker 和 Kubernetes 部署引擎，这些 playbooks 可以独立执行，使用`ansible-playbook`命令，或者使用`ansible-container
    run`命令。让我们运行我们的项目，并通过`ansible-container run`命令将其部署到 OpenShift：
- en: '[PRE27]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Upon successful completion of the playbook run, we can log in to the OpenShift
    web user interface to look at the deployment we just executed. In a web browser,
    navigate to the URL provided in the output of the `minishift start` command (in
    my case, it is `192.168.99.100`), accept the self-signed certificate, and log
    in as the `developer` user:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在playbook运行成功完成后，我们可以登录到OpenShift网页用户界面，查看刚才执行的部署。在网页浏览器中，导航到`minishift start`命令输出中提供的URL（在我的例子中是`192.168.99.100`），接受自签名证书，并以`developer`用户身份登录：
- en: '![](img/e2e97279-fcd3-47a3-9978-d3688f7efa3c.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e2e97279-fcd3-47a3-9978-d3688f7efa3c.png)'
- en: 'Figure 2: Logging into the OpenShift console'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：登录到OpenShift控制台
- en: 'Upon logging in, you should see a new project has been created, called database.
    In this project you can see everything that the Ansible Container deployment has
    generated by default:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 登录后，您应该看到一个新项目已创建，名为`database`。在此项目中，您可以看到Ansible Container部署默认生成的所有内容：
- en: '![](img/38260fa4-260a-460b-a698-c2336770d800.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/38260fa4-260a-460b-a698-c2336770d800.png)'
- en: 'Figure 3: The database project has been created under My Projects in the OpenShift
    console'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：数据库项目已在OpenShift控制台的“我的项目”下创建
- en: 'Clicking on the project, `database` will bring you to a dashboard showing the
    relevant details for the deployment:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 点击项目，`database`将带你进入一个仪表盘，显示与部署相关的详细信息：
- en: '![](img/0209240b-cc70-4315-84d7-fd71d2297ed8.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0209240b-cc70-4315-84d7-fd71d2297ed8.png)'
- en: 'Figure 4: MariaDB database deployment'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：MariaDB数据库部署
- en: As you can see, by default the Ansible Container playbooks used to deploy OpenShift
    run with a very useable set of default configuration options. Right away, we can
    see that Ansible Container has created a new project for our project, called `database`.
    Within this project, a default deployment exists that has our MariaDB pod created
    and running. It has even taken the steps for us to create a default service with
    a pre-configured set of labels, and created a route to access the service using
    the `nip.io` DNS service. Essentially, our new service is deployed and ready to
    go right out-of-the-box. In order to use the OpenShift deployment engine, we didn't
    actually have to change any of the `container.yml` configuration; we used exactly
    the same configuration we used to deploy to Kubernetes, with the exception of
    using a different Kubernetes config file, and specifying the OpenShift engine
    in our `run` command. As I'm sure you can see, having the ability to deploy to
    OpenShift or Kubernetes transparently is immensely powerful. This allows Ansible
    Container to function seamlessly no matter what target architecture your service
    is configured to use.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，默认情况下，用于部署OpenShift的Ansible Container playbooks运行时具有一组非常实用的默认配置选项。我们可以立刻看到，Ansible
    Container为我们的项目创建了一个名为`database`的新项目。在此项目中，存在一个默认部署，其中包含我们创建并正在运行的MariaDB pod。它甚至为我们采取了创建一个默认服务的步骤，预先配置了标签，并使用`nip.io`
    DNS服务创建了一个路由来访问该服务。实际上，我们的新服务已经部署并准备好随时使用。为了使用OpenShift部署引擎，我们实际上不需要更改任何`container.yml`配置；我们使用的配置与部署到Kubernetes时完全相同，唯一的区别是使用了不同的Kubernetes配置文件，并在`run`命令中指定了OpenShift引擎。正如您所看到的，能够透明地部署到OpenShift或Kubernetes是极其强大的。这使得Ansible
    Container能够无缝地工作，无论您的服务配置使用的是哪种目标架构。
- en: 'We can also validate the deployment by using the OC command-line interface
    client. From the Vagrant lab VM, you can use the `oc project` command to switch
    to the `database` project:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过使用OC命令行界面客户端来验证部署。在Vagrant实验室虚拟机中，您可以使用`oc project`命令切换到`database`项目：
- en: '[PRE28]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Once we have switched to a new project context, we can use the `oc get all`
    command to show everything configured to run in this project, including the pods,
    services, and route configuration generated by Ansible Container:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们切换到新的项目上下文，就可以使用`oc get all`命令来显示在该项目中配置的所有内容，包括由Ansible Container生成的pods、服务和路由配置：
- en: '[PRE29]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Along with `ansible-container run`, we can also use the standard Ansible Container
    workflow commands to manage our deployment, such as `stop`, `restart`, and `destroy`.
    As we discussed earlier, these workflow commands function identically with the
    Kubernetes engine. Let''s first start the `ansible-container stop` command. `stop`
    will gracefully stop all running pods in the deployment, while keeping the other
    resources deployed and active. Let''s try stopping the deployment and re-running
    the `get all` command to learn what happens:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`ansible-container run`之外，我们还可以使用标准的Ansible Container工作流命令来管理我们的部署，比如`stop`、`restart`和`destroy`。正如我们之前讨论的，这些工作流命令在Kubernetes引擎中也能以相同的方式工作。让我们首先启动`ansible-container
    stop`命令。`stop`将优雅地停止部署中所有正在运行的Pods，同时保持其他已部署的资源活跃。让我们尝试停止部署并重新执行`get all`命令，了解会发生什么：
- en: '[PRE30]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Once `stop` has completed successfully, re-run the `oc get all` command:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦`stop`命令成功完成，请重新执行`oc get all`命令：
- en: '[PRE31]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: From the preceding output, we can see that OpenShift has created a new revision
    for the configuration change we deployed (`REVISION 2`), which describes the deployment
    as having zero running pod replicas, indicative of the deployment existing in
    the stopped state (`Current 0`, `Desired 0`, `Ready 0`). However, the route and
    service artifacts still exist and are running in the cluster. One of the major
    benefits of OpenShift is the nature of OpenShift to readily track the changes
    made to the project under various revision definitions. This makes it very easy
    to roll back to a previous deployment should a change fail or need to be rolled
    back. Complementary to the `stop` command is the `restart` command, which ensures
    the current revision is in a running state, after first stopping the service.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出中，我们可以看到OpenShift为我们部署的配置更改创建了一个新修订版本（`REVISION 2`），它描述了该部署没有正在运行的Pod副本，表明部署处于停止状态（`Current
    0`，`Desired 0`，`Ready 0`）。然而，路由和服务仍然存在，并且在集群中运行。OpenShift的一个主要优点是，它能够跟踪在各种修订定义下对项目所做的更改。这使得在变更失败或需要回滚时，能够轻松地回退到先前的部署。`stop`命令的补充命令是`restart`，它确保在首先停止服务后，当前修订版本处于运行状态。
- en: 'Unlike `stop`, `restart` does not create a new revision, since our current
    revision is already scaled down to zero replicas, but instead will scale up the
    current revision to ensure that the desired number of pods is running in the project.
    Let''s execute the `ansible-container restart` command for the OpenShift engine
    and see how this affects our deployment:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 与`stop`不同，`restart`不会创建新的修订版本，因为我们当前的修订版本已经缩减为零副本，但会将当前修订版本扩展，以确保在项目中运行所需数量的Pods。让我们执行`ansible-container
    restart`命令，查看它如何影响我们的部署：
- en: '[PRE32]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Executing the `oc get all` command once more, we will see that our current
    revision (#2) is now running with the desired number of pods:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 再次执行`oc get all`命令，我们将看到当前的修订版本（#2）已经按所需的Pod数量运行：
- en: '[PRE33]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Finally, we can use the `ansible-container destroy` command to completely remove
    all traces of our service from the OpenShift (or Kubernetes) cluster. Keep in
    mind that this will also remove the project as well as any other containers that
    are also running within the project that may have been deployed manually or by
    other means outside of Ansible Container. This is why it is important to separate
    application deployments by OpenShift project and Kubernetes namespace, especially
    when running commands such as `ansible-container destroy`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用`ansible-container destroy`命令彻底删除OpenShift（或Kubernetes）集群中所有与我们服务相关的痕迹。请记住，这还将删除项目以及任何其他在项目中运行的容器，无论这些容器是通过Ansible
    Container手动部署还是通过其他方式部署的。这就是为什么在运行诸如`ansible-container destroy`等命令时，将应用程序部署按OpenShift项目和Kubernetes命名空间进行区分非常重要的原因：
- en: '[PRE34]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'According to the task execution, it appears that a single task that was run
    deleted the entire OpenShift project. This is reflected if we execute the `oc
    get all` command one final time:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 根据任务执行情况，似乎有一个任务执行时删除了整个OpenShift项目。如果我们最后一次执行`oc get all`命令，这一点会显现出来：
- en: '[PRE35]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: These errors indicate that our user can no longer list anything that exists
    inside of the `database` project due to the fact that it no longer exists. All
    traces of the project, deployments, services, pods, and routes, have been deleted
    from the cluster. This is also apparent from the web interface because refreshing
    the web page will indicate that the projects no longer exist.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这些错误表明我们的用户已经无法列出 `database` 项目中存在的任何内容，因为该项目不再存在。该项目的所有痕迹，包括部署、服务、Pod 和路由，都已从集群中删除。从
    Web 界面上也可以明显看出这一点，因为刷新网页后会显示该项目已经不存在。
- en: References
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '**Ansible Container Deployment Guide**: [https://docs.ansible.com/ansible-container/reference/deploy.html](https://docs.ansible.com/ansible-container/reference/deploy.html)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ansible Container 部署指南**: [https://docs.ansible.com/ansible-container/reference/deploy.html](https://docs.ansible.com/ansible-container/reference/deploy.html)'
- en: '**VirtualBox Networking Guide**: [https://www.virtualbox.org/manual/ch06.html](https://www.virtualbox.org/manual/ch06.html)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VirtualBox 网络指南**: [https://www.virtualbox.org/manual/ch06.html](https://www.virtualbox.org/manual/ch06.html)'
- en: Summary
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Over the course of this chapter, we looked at the final Ansible Container workflow
    command: `ansible-container deploy`. `deploy` is one of the most versatile commands
    available in the Ansible Container arsenal since it allows us to run and manage
    containers in production-grade Kubernetes and OpenShift environments. `deploy`
    opens a new path in our journey to enable the flexibility and agility that containers
    give our infrastructure. We can now truly use a single tool to not only build
    and debug containerized applications locally, but also to deploy and manage these
    same applications in production. Having the ability to use the same expressive
    Ansible Playbook language to truly build reliable and scalable applications means
    that deployments can be built around DevOps and automation best practices from
    day one, instead of the painstaking task of re-engineering deployments so they
    are automated after the fact.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们研究了最后一个 Ansible Container 工作流命令：`ansible-container deploy`。`deploy` 是
    Ansible Container 中最通用的命令之一，因为它允许我们在生产级的 Kubernetes 和 OpenShift 环境中运行和管理容器。`deploy`
    为我们的旅程开辟了一条新路，能够实现容器赋予我们基础设施的灵活性和敏捷性。现在，我们可以真正地使用一个工具，不仅在本地构建和调试容器化应用，还可以在生产环境中部署和管理这些应用。能够使用相同的表达式
    Ansible Playbook 语言来真正构建可靠且可扩展的应用程序，意味着部署可以从第一天起围绕 DevOps 和自动化最佳实践构建，而不是事后重新设计部署以使其自动化的艰难任务。
- en: Just because we have finished learning about the major Ansible Container workflow
    components does not mean that our journey has ended. So far in this book, we have
    looked at using Ansible Container to deploy single-function microservices that
    require no dependencies on other services. Ansible Container being as powerful
    as it is also has the innate ability to build and deploy multiple containerized
    applications by expressing links and dependencies on other services. In the next
    chapter, we will look at how to build and deploy multi-container applications.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅因为我们已经完成了关于主要的 Ansible Container 工作流组件的学习，并不意味着我们的旅程已经结束。到目前为止，在本书中，我们已经研究了如何使用
    Ansible Container 部署不依赖于其他服务的单功能微服务。Ansible Container 的强大之处在于，它还具有通过表达与其他服务的链接和依赖关系来构建和部署多个容器化应用的内在能力。在下一章，我们将研究如何构建和部署多容器应用。
